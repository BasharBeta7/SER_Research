{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this notebook contains the following sections :\n",
    "## 1. prepare dataset for speech emotion recognition \n",
    "## 2. build a transformer encoder classifier\n",
    "## 3. training the model on initial hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 1: prepare the dataset\n",
    "we will use a famous dataset [IEMOCAP] for speech emotion recognition in order to assess the performance of our model, and then we try to fine-tune it on the actual final dataset.\n",
    "[IEMOCAP] consists of 5 acted sessions of speech, each including a range of 9 emotions, in a total of 12 hours of speech, divided into sentences (each of 3 seconds max).\n",
    "each sentence is annotated by experts and clissified into one of many emotions : anger, happiness, sadness, neutral ..\n",
    " \n",
    " first, we will prepare folder tree, we implement this by copying necessary audio files (sentences) from the dataset into a specified directory (TARGET_PATH). folder tree is as follows:\n",
    "    \n",
    "    root:\n",
    "    ---- /IEMOCAP\n",
    "    ---- ---- /Session1\n",
    "    ---- ---- ---- /EmoEval\n",
    "    ---- ---- ---- /Sentences\n",
    "    ---- ---- /Session2\n",
    "    ---- ---- ---- /EmoEval\n",
    "    ---- ---- ---- /Sentences\n",
    "    ---- ---- /Session3\n",
    "    ---- ---- ---- /EmoEval\n",
    "    ---- ---- ---- /Sentences\n",
    "    ---- ---- /Session4\n",
    "    ---- ---- ---- /EmoEval\n",
    "    ---- ---- ---- /Sentences\n",
    "    ---- ---- /Session5\n",
    "    ---- ---- ---- /EmoEval\n",
    "    ---- ---- ---- /Sentences\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we need to import all necessary packages\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import shutil\n",
    "import librosa\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.utils.data as torchdata \n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "import time \n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#constant files are global UPPERCASE\n",
    "TARGET_PATH = \"../Datasets/IEMOCAP\"\n",
    "SRC_PATH = \"../Datasets/IEMOCAP_full_release\"\n",
    "\n",
    "def prepare_directory(src_dataset, trg_dataset):\n",
    "    \"\"\"\n",
    "    prepare dataset_folder as folllow:\n",
    "    trg_dataset contains 5 sessions, each session folder containes 2 subfolders : EmoEval, Sentences\n",
    "    - EmoEval has the values of (filename, emotion label)\n",
    "    - Sentences containes the .wav files \n",
    "    \"\"\"\n",
    "    os.makedirs(trg_dataset, exist_ok=True)\n",
    "    for dir_path, dir_names, filenames in os.walk(src_dataset):\n",
    "        folder_names = dir_path.split(sep=\"/\")\n",
    "        \n",
    "        if folder_names[-1] == \"EmoEvaluation\":\n",
    "            for file in filenames:\n",
    "                target_path = os.path.join(trg_dataset,folder_names[-3],\"EmoEval\")\n",
    "                os.makedirs(target_path, exist_ok=True)\n",
    "                current_path = os.path.join(dir_path, file)\n",
    "                shutil.copy(current_path, target_path)\n",
    "                \n",
    "                \n",
    "        if folder_names[-2] == \"sentences\" and folder_names[-1] == 'wav':\n",
    "            target_path = os.path.join(trg_dataset,folder_names[-3],\"Sentences\")\n",
    "            for d in dir_names:\n",
    "                current_path = os.path.join(dir_path, d)\n",
    "                shutil.copytree(current_path, target_path, symlinks=False, ignore=None, ignore_dangling_symlinks=False, dirs_exist_ok=True)\n",
    "\n",
    "    \n",
    "prepare_directory(SRC_PATH, TARGET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 9 target classification were recorded in the dataset, first we will enumerate them to get a dictionary {emotion : label }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"angry, happy, sad, neutral, frustrated, excited, fearful, disgusted, other\".split(\",\")\n",
    "y = sorted(y)\n",
    "y = [i.strip() for i in y]\n",
    "x = [f[0:3] for f in y]\n",
    "x = dict.fromkeys(x)\n",
    "for i, j in enumerate(x.keys()):\n",
    "    x[j] = i\n",
    "    \n",
    "label_index = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Folder: ../Datasets/IEMOCAP/Session3/EmoEval: 100%|█████████████████████████████████████████████████| 32/32 [00:01<00:00, 19.29it/s]\n",
      "Reading Folder: ../Datasets/IEMOCAP/Session5/EmoEval:   6%|███▏                                              | 2/31 [00:00<00:01, 19.37it/s]/tmp/ipykernel_12354/570616211.py:42: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  librosa.load(track_path)\n",
      "Reading Folder: ../Datasets/IEMOCAP/Session5/EmoEval: 100%|█████████████████████████████████████████████████| 31/31 [00:01<00:00, 22.88it/s]\n",
      "Reading Folder: ../Datasets/IEMOCAP/Session4/EmoEval: 100%|█████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.59it/s]\n",
      "Reading Folder: ../Datasets/IEMOCAP/Session1/EmoEval: 100%|█████████████████████████████████████████████████| 28/28 [00:01<00:00, 19.66it/s]\n",
      "Reading Folder: ../Datasets/IEMOCAP/Session2/EmoEval: 100%|█████████████████████████████████████████████████| 30/30 [00:01<00:00, 20.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output location: ../Datasets/IEMOCAP/json/data.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#prepare json file that stores filenames, genders, and labels from all sessions of the dataset\n",
    "\n",
    "\n",
    "ROOT_PATH = \"../Datasets/IEMOCAP\"\n",
    "JSON_PATH = \"../Datasets/IEMOCAP/json/data.json\"\n",
    "\n",
    "\n",
    "def prepare_json(src_path, trg_path):\n",
    "    '''read dataset folder to extract a json file containing the filenames, gender, and label of each sentence'''\n",
    "        \n",
    "    \n",
    "    global filenames_labels\n",
    "    filenames_labels = {\n",
    "        \"filenames\" : [],\n",
    "        \"genders\" : [],\n",
    "        \"labels\" : []\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for dir_path, dir_names, filenames in os.walk(src_path):\n",
    "        # if current dir is Session_i      \n",
    "        folder_names = dir_path.split(sep=\"/\")\n",
    "        if folder_names[-1] == \"EmoEval\":\n",
    "            for f in tqdm.tqdm(filenames, desc=\"Reading Folder: {}\".format(dir_path), ncols=140):\n",
    "                if f.split(\".\")[-1] == \"txt\":\n",
    "                    current_path = os.path.join(dir_path, f)\n",
    "                    with open(current_path, \"r\") as fr:\n",
    "                        for l in fr:\n",
    "                            reg = re.findall(\"\\[\\d+.\\d+ \\- \\d+.\\d+\\]\", l)\n",
    "                            \n",
    "                            if reg is not None:\n",
    "                                splits = l.split()\n",
    "                                if len(splits) < 5:\n",
    "                                    continue\n",
    "                                sentence_path = splits[3]\n",
    "                                emo = splits[4]\n",
    "                                \n",
    "                                if emo in label_index:\n",
    "                                    track_path = os.path.join(dir_path, '../Sentences', sentence_path + \".wav\")\n",
    "                                  \n",
    "                                    try:\n",
    "                                        librosa.load(track_path)\n",
    "                                        filenames_labels[\"filenames\"].append(track_path)\n",
    "                                        filenames_labels[\"genders\"].append(sentence_path[-4])\n",
    "                                        filenames_labels[\"labels\"].append(label_index[emo])\n",
    "                                    except:\n",
    "                                         pass\n",
    "                                \n",
    "        if dir_path.split(sep=\"/\")[-1][:-1] == \"Session\" :\n",
    "            session_number = dir_path.split(sep=\"/\")[-1][-1]\n",
    "            current_path = os.path.join(dir_path, 'dialog/EmoEvaluation/Categorical')\n",
    "    \n",
    "    os.makedirs(os.path.dirname(track_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(trg_path), exist_ok=True)\n",
    "    with open(trg_path, 'w+') as fp:\n",
    "        json.dump(filenames_labels, fp, indent=4)\n",
    "    \n",
    "    \n",
    "    print(\"output location: {}\".format(trg_path))\n",
    "    return filenames_labels[\"labels\"]\n",
    "        \n",
    "\n",
    "    \n",
    "files = prepare_json(ROOT_PATH, JSON_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have our json file, which contains filepaths and labels of each audio segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7135"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(files) > 0, print('json file is empty!') # to make sure that everything is fine \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - feature extraction:\n",
    "\n",
    "numerous options can be used as features for audio signals, such as MFCC, mel-bins, Delta_MFCC, Spectogram .. \n",
    "we can experiment with different features after building the model. For now we will implement two feature-extracting functions: \n",
    "1. extracts MFCC + Delta_MFCC for a total of 26-dim features vector for each stride of audio\n",
    "(def 'extract_MFCC_delta'). \n",
    "2. extracts mel-bins features for a total of 64-dim feature vector for each strided of audio\n",
    "(def 'extract_mel_bins')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio data preprocessing consists of : voice activity detection to remove silences from beginning and end of each audio utterance. then data-segmenting to obtain fixed-length audio utterances as inputs. Each utterance is windowed into many segments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will adapt similar approach to : \n",
    "@ARTICLE{gong_psla, \n",
    "    author={Gong, Yuan and Chung, Yu-An and Glass, James},  \n",
    "    journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},   \n",
    "    title={PSLA: Improving Audio Tagging with Pretraining, Sampling, Labeling, and Aggregation},   \n",
    "    year={2021}, \n",
    "    doi={10.1109/TASLP.2021.3120633}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MFCC_delta(waveform, sr, win_size=0.025, stride=0.01, n_mfcc=13):\n",
    "    \"\"\"\n",
    "     extract 13 MFCC + 13 Delta_MFCC as low level descriptors \n",
    "    :param track_path: path of the audio track\n",
    "    :param win_size: length of the hamming window (in seconds)\n",
    "    :param stride: stride length (in seconds)\n",
    "    :param n_mfcc: number of desired mel frequency cepstral coefficients\n",
    "    :returns : spectogram of mfcc+elta features\n",
    "    \"\"\"\n",
    "    \n",
    "    #specifty parameters of mfcc\n",
    "    n_fft = int(win_size*sr)\n",
    "    hop_length = int(stride*sr)\n",
    "    \n",
    "    # get mfcc, deltas \n",
    "    MFCC = librosa.feature.mfcc(y=waveform,\n",
    "                                n_mfcc=n_mfcc,\n",
    "                                n_fft=n_fft,\n",
    "                                hop_length=hop_length)\n",
    "    \n",
    "    MFCC_delta = librosa.feature.delta(MFCC)\n",
    "    #librosa.display.specshow(MFCC, x_axis=\"time\")\n",
    "    #plt.colorbar()\n",
    "    #plt.xlabel('time')\n",
    "    #plt.ylabel('MFCC')\n",
    "    \n",
    "    MFCC = MFCC\n",
    "    MFCC_delta = MFCC_delta\n",
    "    \n",
    "    features = np.vstack((MFCC, MFCC_delta))\n",
    "    print(\"features shape is : {}\".format(features.shape))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 364)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def extract_mel_bins(waveform, sr, win_size=0.025, stride=0.01, n_mels= 64):\n",
    "    '''extract MEL frequency bins as features of the waveform'''\n",
    "    mel_spectorgram = torchaudio.transforms.MelSpectrogram(sample_rate=sr,\n",
    "                                                    n_fft=int(win_size*sr),\n",
    "                                                   hop_length=int(stride*sr),\n",
    "                                                   n_mels= n_mels)\n",
    "    features = mel_spectorgram(waveform)\n",
    "    features = np.array(features)\n",
    "    features = np.squeeze(features, axis=0)\n",
    "    return features\n",
    "\n",
    "waveform, sr = torchaudio.load(\"/home/bashar/Study/Research_SER/Notebook/Ses03F_impro01_F004.wav\")\n",
    "extract_mel_bins(waveform, sr).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we want to process waveforms inside a torch dataset, the following class extracts waveforms from json file, resamples each waveform into a unified sample rate, and fix the length of all wave forms by zero padding. Finally, it extracts features of the waveform by calling a feature extraction user-defined function (here we used mel-bins features which are extracted by caling 'extract_mel_bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SAMPLE_RATE=22050\n",
    "NUM_SAMPLES = 3 * SAMPLE_RATE\n",
    "JSON_PATH = \"../Datasets/IEMOCAP/json/data.json\"\n",
    "\n",
    "class SER_dataset(Dataset):\n",
    "    def pad_cut_if_necessary(self, waveform):\n",
    "        # check length of wave form\n",
    "        wav_length = waveform.shape[1]\n",
    "        \n",
    "        # if longer, cut the waveform\n",
    "        if wav_length > self.num_samples:\n",
    "            waveform = waveform[:, :self.num_samples]\n",
    "            \n",
    "        # if shorter, pad the waveform with zeros\n",
    "        if wav_length < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - wav_length\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, num_missing_samples))\n",
    "   \n",
    "        return waveform\n",
    "  \n",
    "    \n",
    "    def __init__(self, json_config_file, transformation,  num_samples=NUM_SAMPLES):\n",
    "        \"\"\"\n",
    "        :param json_config_file : .json file which includes tracks paths and their labels\n",
    "        :param transformation : a function pointer that will be used to extract features from input audio signals\n",
    "        :num_samples : total number of samples allowed for the input\"\"\"\n",
    "        with open(json_config_file, 'r') as pf:\n",
    "            data = json.load(pf)\n",
    "            \n",
    "        self.filenames = data[\"filenames\"]\n",
    "        self.labels = data[\"labels\"]\n",
    "        self.num_samples = num_samples\n",
    "        self.transformation = transformation\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # get waveform from current index\n",
    "        waveform, sr = torchaudio.load(self.filenames[index])\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq= SAMPLE_RATE)\n",
    "        waveform = resampler(waveform)\n",
    "        waveform = (waveform)\n",
    "        waveform = self.pad_cut_if_necessary(waveform)\n",
    "        features = self.transformation(waveform, sr)\n",
    "        \n",
    "        # get label of the current index\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return features, label\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each input is of shape: (64, 414)\n"
     ]
    }
   ],
   "source": [
    "# define our set of (features, targets) \n",
    "my_set = SER_dataset(JSON_PATH, transformation=extract_mel_bins)\n",
    "print(f\"each input is of shape: {my_set[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 2. build a transformer encoder classifier\n",
    "\n",
    "### this section covers the architecture for the classifier. Which is based on a transformer model that uses multi-head attention.\n",
    "\n",
    "this layer applies 1d convolution on the spectogram, to get the embeddings of each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 128, 1, 40]         131,200\n",
      "================================================================\n",
      "Total params: 131,200\n",
      "Trainable params: 131,200\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.10\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 0.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class input_embedding(nn.Module):\n",
    "    def __init__(self, d_input, d_model, stride=10, kernel_size=16):\n",
    "        \"\"\"\n",
    "        :param d_input: feature-vector dimension of input spectogram\n",
    "        :param d_model: output dimension of the embeddings\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(1, d_model, kernel_size=(d_input, kernel_size), stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input of shape [B, d_input, t_length]\n",
    "        return : output of shape [B, max_length, d_model]\"\"\"\n",
    "        # we need to add new axis for number of channels\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        # we apply the projection layer\n",
    "        x = self.proj(x)\n",
    "        # we remove the height dimension, because it is always equal to 1 \n",
    "        x = torch.squeeze(x, dim=2)\n",
    "        #x = torch.einsum('bij->bji', x)\n",
    "        x = x.transpose(1,2)\n",
    "        return x\n",
    "\n",
    "    \n",
    "inp = torch.randn([5, 64, 414])\n",
    "embed = input_embedding(64, 128)\n",
    "summary(embed, (64, 414))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will work on positional encoding PE, which is added to the output of the projection layer (AKA embeddings) to capture the positional information of the input audio.\n",
    "the theory behind this positional encoding techniques is derived from the paper \"Attention is all you need\"\n",
    "\n",
    "PE(pos,2i) = sin(pos/(1000^(2i/d_model))\n",
    "PE(pos,2i+1) = cos(pos/(1000^(2i/d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional encoding :\n",
    "from torchsummary import summary\n",
    "\n",
    "class PositionalEncoding( nn.Module ):\n",
    "    \"\"\"\n",
    "    a nn.Module wrapper to extract Position embeddings with a specific dimnesionality\n",
    "    \"\"\"\n",
    "    def __init__(self,d_model, max_length):\n",
    "        \"\"\"\n",
    "        :param max_length: number of columns of input embedding \n",
    "        :param d_model: number of rows to represent input features of the transformer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # get the length of sequency from input\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        even_den = pow(10000, even_i/self.d_model)\n",
    "        pos = torch.arange(seq_len).float().unsqueeze(1)\n",
    "        \n",
    "        even_pe = torch.sin(pos/even_den)\n",
    "        odd_pe = torch.cos(pos/even_den)\n",
    "        stacked = torch.stack([even_pe, odd_pe], dim=2)\n",
    "        stacked = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return stacked\n",
    " \n",
    "pe = PositionalEncoding(128,40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build the Transformer encoder blocks, which consists of multi-headed attention layer, followed by a feed-forward layer (as in the paper \"Attention is all you need\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiHeadSplit(nn.Module):\n",
    "    \"\"\"split the input data into multiple heads using linear layers\"\"\"\n",
    "    def __init__(self, d_model:int, d_k:int, heads:int= 8, bias=False):\n",
    "        \"\"\"\n",
    "        :param d_model: input feature dimension\n",
    "        :param d_k: dimension of each head \n",
    "        :param heads: number of heads to split each input sample into\n",
    "        :param bias: whether to apply bias term into linear layer\"\"\"\n",
    "        super().__init__()\n",
    "        # copy params into local attributes of the class\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.heads = heads\n",
    "\n",
    "        # assert that numbers check\n",
    "        assert(self.d_k * self.heads == self.d_model), \"heads number isn't compatible with dimesions!\"\n",
    "        \n",
    "        \n",
    "        # create a linear layer to create the different heads\n",
    "        self.linear = nn.Linear(d_model, heads * d_k, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"x is of shape [-1, seq_length, d_model]\"\"\"\n",
    "        # change the view of the input so that trainable features (d_model) is the last\n",
    "        shape = x.shape[:-1]\n",
    "        # split x into multiple heads\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        \n",
    "        # split last dimension into two \n",
    "        x = x.view(*shape, self.heads, self.d_k)\n",
    "        x = torch.transpose(x, -2, -3)\n",
    "        \n",
    "\n",
    "        # return output\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 40, 128]          16,384\n",
      "================================================================\n",
      "Total params: 16,384\n",
      "Trainable params: 16,384\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 0.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mh = MultiHeadSplit(128, 16)\n",
    "summary(mh, (40, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we will create the scaled dot-product attention layer, which will be used to extract meaningful relations between different parts of the audio track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, heads, d_k, bias=False, dropout=0.1): # dropout is set randomly \n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "        \n",
    "        # split input into three matrecies : q: query, k: key, v: value using linear layers\n",
    "        self.query = MultiHeadSplit(d_model, d_k, heads, bias)\n",
    "        self.key = MultiHeadSplit(d_model, d_k, heads, bias)\n",
    "        self.value = MultiHeadSplit(d_model, d_k, heads, bias)\n",
    "        \n",
    "        # define necessery activations\n",
    "        self.softmax = nn.Softmax(dim= -1) # the input to the softmax has shape (t_dim, t_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = 1 / (self.d_k)**(0.5)\n",
    "        \n",
    "        output = nn\n",
    "        \n",
    "    def get_att(self, q, k):\n",
    "        \"\"\"\n",
    "        q shape (B, h, q_len, d)\n",
    "        k shape (B, h, k_len, d)\n",
    "        \n",
    "        :return : output of shape (B, h, q_len, k_len)\n",
    "            \"\"\"\n",
    "        out = torch.einsum('bhqd,bhkd->bhqk', q, k)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        :param x : input of shape (B, seq_length, d_model) \n",
    "        :param mask : mask of shape (B, seq_length)\n",
    "        \n",
    "        :return output of shape (B, seq_length, d_v)\n",
    "        \"\"\"\n",
    "                \n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        \n",
    "        # apply matmul\n",
    "        att = self.get_att(q, k)\n",
    "        \n",
    "        # apply scale\n",
    "        att = att * self.scale\n",
    "        \n",
    "      \n",
    "        \n",
    "        # apply mask\n",
    "        if mask is not None:\n",
    "            att = att.masked_fill(mask==0, -1 * torch.inf)\n",
    "            \n",
    "        # apply softmax\n",
    "        att = self.softmax(att)\n",
    "        \n",
    "        # apply matmul\n",
    "        att = torch.einsum('bhqk,bhkd->bqhd', att, v)\n",
    "        \n",
    "        # concatenate all heads in one (bhqd -> bq(d*h)\n",
    "        shape = att.shape[:-2]\n",
    "\n",
    "        out = att.reshape(*shape, att.shape[-1] * att.shape[-2])\n",
    "\n",
    "        \n",
    "        return out\n",
    "    \n",
    "  \n",
    "        \n",
    "from torchsummary import summary \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1             [-1, 40, 1024]         132,096\n",
      "           Dropout-2             [-1, 40, 1024]               0\n",
      "            Linear-3              [-1, 40, 128]         131,200\n",
      "================================================================\n",
      "Total params: 263,296\n",
      "Trainable params: 263,296\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.66\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 1.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# next we will implement the feed forward layer \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, n_hidden, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_hidden number of feed forward features in the hidden layer\"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        # First linear layer\n",
    "        self.linear1 = nn.Linear(d_model, n_hidden)\n",
    "        \n",
    "        #Second Linear layer\n",
    "        self.linear2 = nn.Linear(n_hidden, d_model)\n",
    "        \n",
    "        #dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply first linear\n",
    "        x = self.linear1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "ff = FeedForward(128, 1024)\n",
    "summary(ff, (40, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         LayerNorm-1              [-1, 40, 128]             256\n",
      "================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(normalized_shape=input_shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.norm(x)\n",
    "    \n",
    "n = LayerNorm((128))\n",
    "summary(n, (40,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 40, 128]          16,384\n",
      "    MultiHeadSplit-2            [-1, 8, 40, 16]               0\n",
      "            Linear-3              [-1, 40, 128]          16,384\n",
      "    MultiHeadSplit-4            [-1, 8, 40, 16]               0\n",
      "            Linear-5              [-1, 40, 128]          16,384\n",
      "    MultiHeadSplit-6            [-1, 8, 40, 16]               0\n",
      "           Softmax-7            [-1, 8, 40, 40]               0\n",
      "     SelfAttention-8              [-1, 40, 128]               0\n",
      "         LayerNorm-9              [-1, 40, 128]             256\n",
      "        LayerNorm-10              [-1, 40, 128]               0\n",
      "          Dropout-11              [-1, 40, 128]               0\n",
      "           Linear-12             [-1, 40, 1024]         132,096\n",
      "          Dropout-13             [-1, 40, 1024]               0\n",
      "           Linear-14              [-1, 40, 128]         131,200\n",
      "      FeedForward-15              [-1, 40, 128]               0\n",
      "        LayerNorm-16              [-1, 40, 128]             256\n",
      "        LayerNorm-17              [-1, 40, 128]               0\n",
      "          Dropout-18              [-1, 40, 128]               0\n",
      "================================================================\n",
      "Total params: 312,960\n",
      "Trainable params: 312,960\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.19\n",
      "Estimated Total Size (MB): 2.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# now we implement the encoder block \n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This layer consists of self attention layer, followed by add and norm layer, then a feed forward layer, followed by add and norm layer \"\"\"\n",
    "    def __init__(self, d_model, d_k, heads, n_hidden=1024, dropout=0.1, bias=False):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "        self.bias = bias\n",
    "        \n",
    "        # define a self attention layer\n",
    "        self.self_attention = SelfAttention(d_model, heads, d_k, bias, dropout)\n",
    "        \n",
    "        # norm layer\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        \n",
    "        # feed forward layer\n",
    "        self.ff = FeedForward(d_model, n_hidden=n_hidden,dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x has a shape of (B, seq_length, d_model)\"\"\"\n",
    "        \n",
    "        att = self.self_attention(x)\n",
    "        \n",
    "        x = self.norm1(x + att)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        ff = self.ff(x)\n",
    "        \n",
    "        x = self.norm2(x + ff)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "enc = EncoderBlock(128, 16, 8)\n",
    "\n",
    "summary(enc, (40, 128))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 40, 128]          16,384\n",
      "    MultiHeadSplit-2            [-1, 8, 40, 16]               0\n",
      "            Linear-3              [-1, 40, 128]          16,384\n",
      "    MultiHeadSplit-4            [-1, 8, 40, 16]               0\n",
      "            Linear-5              [-1, 40, 128]          16,384\n",
      "    MultiHeadSplit-6            [-1, 8, 40, 16]               0\n",
      "           Softmax-7            [-1, 8, 40, 40]               0\n",
      "     SelfAttention-8              [-1, 40, 128]               0\n",
      "         LayerNorm-9              [-1, 40, 128]             256\n",
      "        LayerNorm-10              [-1, 40, 128]               0\n",
      "          Dropout-11              [-1, 40, 128]               0\n",
      "           Linear-12             [-1, 40, 1024]         132,096\n",
      "          Dropout-13             [-1, 40, 1024]               0\n",
      "           Linear-14              [-1, 40, 128]         131,200\n",
      "      FeedForward-15              [-1, 40, 128]               0\n",
      "        LayerNorm-16              [-1, 40, 128]             256\n",
      "        LayerNorm-17              [-1, 40, 128]               0\n",
      "          Dropout-18              [-1, 40, 128]               0\n",
      "     EncoderBlock-19              [-1, 40, 128]               0\n",
      "================================================================\n",
      "Total params: 312,960\n",
      "Trainable params: 312,960\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.35\n",
      "Params size (MB): 1.19\n",
      "Estimated Total Size (MB): 2.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the encoder sonsists of a positional embedding block + sequence of n encoder blocks \n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, max_length, d_model, d_k, heads,n_encoders=1, n_hidden=1024, dropout=0.1, bias=False ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.pe = PositionalEncoding(d_model, max_length)\n",
    "      \n",
    "        self.enc_blocks = nn.ModuleList([\n",
    "            EncoderBlock(d_model, d_k, heads, n_hidden, dropout, bias) for i in range(n_encoders)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x): \n",
    "        \"\"\"x is of shape (B, seq_length, d_model)\n",
    "        :return output of shape (B, seq_length, d_model)\"\"\"\n",
    "\n",
    "        seq_length = x[1]\n",
    "        #pe = self.pe()[:seq_length,:]\n",
    "        # add positional information \n",
    "        x = x #+ pe\n",
    "        \n",
    "        # inject new input to encoder blocks \n",
    "        \n",
    "        for layer in self.enc_blocks:\n",
    "            x = layer(x)        \n",
    "        return x\n",
    "        \n",
    "enc = Encoder(40, 128, 16,8)\n",
    "summary(enc, (40,128))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1              [-1, 128, 40]               0\n",
      "         AvgPool1d-2               [-1, 128, 1]               0\n",
      "            Linear-3                    [-1, 5]             645\n",
      "           Softmax-4                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 645\n",
      "Trainable params: 645\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the full architechture consists of : input embedding + encoder + global average \n",
    "# we will experiment with global averaging and cls token [like BERT]\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_classes, d_model, seq_length):\n",
    "        super().__init__()\n",
    "        self.average_pooling = nn.AvgPool1d(kernel_size=seq_length, stride=seq_length)\n",
    "        self.flat = nn.Flatten(start_dim = 1, end_dim=2)\n",
    "        self.linear = nn.Linear(d_model, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        # add channel dimension \n",
    "        x = x.unsqueeze(dim=1)\n",
    "      \n",
    "        # transpose input \n",
    "        x = x.transpose(-1,-2)\n",
    "        \n",
    "        # flatten input \n",
    "        x = self.flat(x)\n",
    "    \n",
    "        # apply avgPool\n",
    "        x = self.average_pooling(x)\n",
    "        \n",
    "        # remove added dimension\n",
    "        x = x.squeeze(dim=-1)\n",
    "        \n",
    "        # apply linear layer \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # apply softmax \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "cls = Classifier(5, 128, 40)\n",
    "summary(cls, (40, 128))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full arch consists of : input embedding + encoder + global average \n",
    "# we will experiment with global averaging and cls token [like BERT]\n",
    "\n",
    "\n",
    "class Classifier2(nn.Module):\n",
    "    def __init__(self, n_classes, d_model, seq_length):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, n_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # apply linear layer \n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # apply softmax \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "cls2 = Classifier2(10, 128, 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will encapsulate the whole work under one class \n",
    "\n",
    "class SERT(nn.Module):\n",
    "    def __init__(self,d_input,\n",
    "                 max_length,\n",
    "                 d_model,\n",
    "                 d_k,\n",
    "                 heads,\n",
    "                 n_classes,\n",
    "                 n_encoders=1,\n",
    "                 n_hidden=1024,\n",
    "                 dropout=0.1,\n",
    "                 bias=False,\n",
    "                 stride=10,\n",
    "                 kernel_size=16 ):\n",
    "        super().__init__()\n",
    "        self.input = input_embedding(d_input, d_model, stride, kernel_size)\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            Encoder(max_length,\n",
    "                    d_model,\n",
    "                    d_k,\n",
    "                    heads,\n",
    "                    n_encoders=1,\n",
    "                    n_hidden=1024,\n",
    "                    dropout=0.1,\n",
    "                    bias=False) for _ in range(n_encoders)\n",
    "        ])\n",
    "        self.output= Classifier(n_classes, d_model, max_length)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        x = self.output(x)\n",
    "        return x\n",
    "        \n",
    "sert_model = SERT(d_input=64, max_length=35, d_model=128,d_k=16,heads=8,n_classes=9)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 3. training the model on initial hyperparameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset is split as follows:\n",
      "\n",
      "train : 4566(0.64)\n",
      "\n",
      "test : 1427(0.36)\n",
      "\n",
      "validation : 1142(0.16)\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we will split the dataset into train_test_validation sets \n",
    "\n",
    "\n",
    "def train_test_val_split(dataset, train_test,train_val):\n",
    "    \"\"\"splits dataset into 3 groups:\n",
    "    1- train dataset (size = train_test*train_val)\n",
    "    2 - test dataset (size = (1-train_test))\n",
    "    3- validation dataset (size = (train_test * (1-train_val))\n",
    "    \"\"\"\n",
    "\n",
    "    train_ds, test_ds = torchdata.random_split(dataset, [int(train_test * len(dataset)), len(dataset) - int(train_test * len(dataset))])\n",
    "    train_ds, val_ds = torchdata.random_split(train_ds, [int(train_val * len(train_ds)), len(train_ds) - int(train_val * len(train_ds))])\n",
    "    train_size = train_test * train_val\n",
    "    test_size = 1 - train_size\n",
    "    val_size = train_test * (1 - train_val)\n",
    "    print(\"dataset is split as follows:\\n\\ntrain : {}({})\\n\\ntest : {}({})\\n\\nvalidation : {}({})\".format(len(train_ds), round(train_size,2), len(test_ds), round(test_size, 2), len(val_ds), round(val_size, 2)))\n",
    "    return train_ds, test_ds, val_ds\n",
    "\n",
    "\n",
    "train,test,val = train_test_val_split(my_set, 0.8, 0.8)\n",
    "\n",
    "# after splitting, we will define the dataloader\n",
    "train_dataloader = torchdata.DataLoader(dataset=train, batch_size=32, shuffle=True)\n",
    "validation_dataloader = torchdata.DataLoader(dataset=val, batch_size=32, shuffle=True)\n",
    "test_dataloader = torchdata.DataLoader(dataset=test, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# specify the optimizer (adam) and the loss function\n",
    "optimizer = torch.optim.Adam(sert_model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "sert_model = sert_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_train(model,train_dataset, val_dataset, num_epochs, device, loss_fn, metric, optimizer, ext_dir):\n",
    "    \"\"\"returns information about the model, the results of training\n",
    "    :param ext_dir: directory to save the state of the best performing model according to the metric function\n",
    "    \"\"\"\n",
    "    \n",
    "    summary = {\n",
    "        'model name': model.__class__.__name__,\n",
    "        'device': device,\n",
    "        'loss_fn': loss_fn,\n",
    "        'metric': metric, \n",
    "        'optimizer':optimizer,\n",
    "        'num_epochs' : num_epochs,\n",
    "        'train_loss' :[],\n",
    "        'train_accuracy': [],\n",
    "        'val_loss' :[],\n",
    "        'val_accuracy' :[],\n",
    "        'steps' :[]\n",
    "    }\n",
    "    \n",
    "    batch_size = train_dataset.batch_size\n",
    "    \n",
    "    print(f\"start training with :\\n total epochs: {num_epochs}\\n batch size: {train_dataset.batch_size}\\n total batches: {len(train_dataset)}\")\n",
    "    \n",
    "    # set a timer to measure the training time \n",
    "    start_timer = time.time()\n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # log stride = 10% of the number of batches to loop through, this is used to print results while training \n",
    "    log_stride = int(0.1 * len(train_dataset))\n",
    "    \n",
    "    # add model graph to tensorboard\n",
    "    batch, _ = next(iter(train_dataset))\n",
    "    writer = SummaryWriter(f\"runs/log_sert_model\")\n",
    "    writer.add_graph(model, batch.to(device))\n",
    "    \n",
    "    \n",
    "    # save the best performing model\n",
    "    max_acc = 0.0\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # we will calculate average loss per epoch, average accuracy per epoch\n",
    "        loss_epoch = 0.0\n",
    "        accuracy_epoch = 0.0\n",
    "        \n",
    "        # average metrics per log_stride\n",
    "        loss_stride = 0.0\n",
    "        correct_stride = 0\n",
    "        \n",
    "        # save metrics for logging\n",
    "        train_loss =[]\n",
    "        train_acc = []\n",
    "        eval_loss = []\n",
    "        eval_acc = []\n",
    "            \n",
    "        model.train()\n",
    "        for it, (X, y) in enumerate(train_dataset):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss =loss_fn(y_pred, y)\n",
    "            loss_stride += loss\n",
    "            train_loss.append((loss, epoch, it))\n",
    "            \n",
    "            \n",
    "            # get correct predictions\n",
    "            predictions = torch.argmax(y_pred, dim=1)\n",
    "           \n",
    "            \n",
    "            correct_stride += (y == predictions).sum().item()\n",
    "            train_acc.append(((correct_stride)/batch_size, epoch, it))\n",
    "            \n",
    "            # zero grad the optim.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if (it + 1) % log_stride == 0:\n",
    "                # print results\n",
    "                print(f\"epoch[{epoch + 1}/{num_epochs}] | batch[{it + 1}/{len(train_dataset)}] train_loss: {loss_stride/ (log_stride):.4f} | accuracy: {correct_stride/(log_stride * batch_size)}\")\n",
    "                \n",
    "                # send scalars to tensorboard\n",
    "                writer.add_scalar('train_loss',loss_stride/ (log_stride), epoch * len(train_dataset) + it)\n",
    "                writer.add_scalar('train accuracy', correct_stride/(log_stride * batch_size), epoch * len(train_dataset) + it)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # reset parameters\n",
    "                loss_epoch += loss_stride\n",
    "                accuracy_epoch += correct_stride\n",
    "                loss_stride = 0.0\n",
    "                correct_stride = 0\n",
    "        \n",
    "        print(\"validation:\")\n",
    "        model.eval()\n",
    "        loss_val = 0.0\n",
    "        acc_val = 0.0\n",
    "        \n",
    "        \n",
    "        with torch.inference_mode() :\n",
    "            correct = 0\n",
    "            for (X_test, y_test) in val_dataset:\n",
    "                X_test = X_test.to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                \n",
    "                y_pred = model(X_test)\n",
    "                loss_val += loss_fn(y_pred, y_test)\n",
    "                predictions = torch.argmax(y_pred, dim=1)\n",
    "                \n",
    "                correct += (predictions == y_test).sum().item()\n",
    "                \n",
    "        eval_loss.append((loss_val / len(val_dataset), epoch))\n",
    "        eval_acc.append(((correct/(len(val_dataset) * batch_size)), epoch))\n",
    "            \n",
    "        train_accuracy = accuracy_epoch/(batch_size * len(train_dataset))\n",
    "        print(f\"epoch: {epoch} summary:\\n train_loss: {loss_epoch / len(train_dataset)}, validation loss: {loss_val / len(val_dataset)}, train accuracy: {accuracy_epoch/(len(train_dataset) * batch_size)}\")\n",
    "        \n",
    "        summary['train_loss'].append(loss_epoch.item() / len(train_dataset))\n",
    "\n",
    "        writer.add_scalar('validation_loss',eval_loss[-1][0],  epoch)\n",
    "        writer.add_scalar('validation_accuracy',eval_acc[-1][0],  epoch)\n",
    "        \n",
    "        summary['val_loss'].append(eval_loss[-1][0].item())\n",
    "        summary['val_accuracy'].append(correct/(len(val_dataset) * batch_size))\n",
    "        summary['steps'].append(epoch)\n",
    "        summary['train_accuracy'].append(accuracy_epoch/(batch_size * len(train_dataset)))\n",
    "\n",
    "        if train_accuracy > max_acc:\n",
    "            max_acc = train_accuracy\n",
    "            torch.save(model.state_dict(), ext_dir)\n",
    "    \n",
    "    total_time = (time.time() - start_timer)\n",
    "    summary['total_time'] = total_time\n",
    "    writer.close()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset is split as follows:\n",
      "\n",
      "train : 4566(0.64)\n",
      "\n",
      "test : 1427(0.36)\n",
      "\n",
      "validation : 1142(0.16)\n",
      "start training with :\n",
      " total epochs: 20\n",
      " batch size: 64\n",
      " total batches: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1/20] | batch[7/72] train_loss: 2.2020 | accuracy: 0.10714285714285714\n",
      "epoch[1/20] | batch[14/72] train_loss: 2.1966 | accuracy: 0.15178571428571427\n",
      "epoch[1/20] | batch[21/72] train_loss: 2.1854 | accuracy: 0.20535714285714285\n",
      "epoch[1/20] | batch[28/72] train_loss: 2.1819 | accuracy: 0.16071428571428573\n",
      "epoch[1/20] | batch[35/72] train_loss: 2.1772 | accuracy: 0.19419642857142858\n",
      "epoch[1/20] | batch[42/72] train_loss: 2.1635 | accuracy: 0.27901785714285715\n",
      "epoch[1/20] | batch[49/72] train_loss: 2.1557 | accuracy: 0.2700892857142857\n",
      "epoch[1/20] | batch[56/72] train_loss: 2.1480 | accuracy: 0.28794642857142855\n",
      "epoch[1/20] | batch[63/72] train_loss: 2.1410 | accuracy: 0.3125\n",
      "epoch[1/20] | batch[70/72] train_loss: 2.1396 | accuracy: 0.29910714285714285\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██▏                                         | 1/20 [00:25<07:55, 25.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 summary:\n",
      " train_loss: 2.108841896057129, validation loss: 2.1283209323883057, train accuracy: 0.2204861111111111\n",
      "epoch[2/20] | batch[7/72] train_loss: 2.1212 | accuracy: 0.2857142857142857\n",
      "epoch[2/20] | batch[14/72] train_loss: 2.1277 | accuracy: 0.27901785714285715\n",
      "epoch[2/20] | batch[21/72] train_loss: 2.1100 | accuracy: 0.3236607142857143\n",
      "epoch[2/20] | batch[28/72] train_loss: 2.1115 | accuracy: 0.29017857142857145\n",
      "epoch[2/20] | batch[35/72] train_loss: 2.1172 | accuracy: 0.2700892857142857\n",
      "epoch[2/20] | batch[42/72] train_loss: 2.0946 | accuracy: 0.2857142857142857\n",
      "epoch[2/20] | batch[49/72] train_loss: 2.0898 | accuracy: 0.30357142857142855\n",
      "epoch[2/20] | batch[56/72] train_loss: 2.0811 | accuracy: 0.33482142857142855\n",
      "epoch[2/20] | batch[63/72] train_loss: 2.0944 | accuracy: 0.3013392857142857\n",
      "epoch[2/20] | batch[70/72] train_loss: 2.0971 | accuracy: 0.29910714285714285\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 2/20 [00:56<08:36, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 summary:\n",
      " train_loss: 2.0460047721862793, validation loss: 2.0875234603881836, train accuracy: 0.2890625\n",
      "epoch[3/20] | batch[7/72] train_loss: 2.0775 | accuracy: 0.32589285714285715\n",
      "epoch[3/20] | batch[14/72] train_loss: 2.0912 | accuracy: 0.30580357142857145\n",
      "epoch[3/20] | batch[21/72] train_loss: 2.0732 | accuracy: 0.33035714285714285\n",
      "epoch[3/20] | batch[28/72] train_loss: 2.0825 | accuracy: 0.3125\n",
      "epoch[3/20] | batch[35/72] train_loss: 2.0924 | accuracy: 0.28794642857142855\n",
      "epoch[3/20] | batch[42/72] train_loss: 2.0675 | accuracy: 0.30580357142857145\n",
      "epoch[3/20] | batch[49/72] train_loss: 2.0641 | accuracy: 0.3325892857142857\n",
      "epoch[3/20] | batch[56/72] train_loss: 2.0543 | accuracy: 0.3482142857142857\n",
      "epoch[3/20] | batch[63/72] train_loss: 2.0718 | accuracy: 0.30357142857142855\n",
      "epoch[3/20] | batch[70/72] train_loss: 2.0764 | accuracy: 0.31026785714285715\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▌                                     | 3/20 [01:27<08:28, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 summary:\n",
      " train_loss: 2.01745343208313, validation loss: 2.069279670715332, train accuracy: 0.3075086805555556\n",
      "epoch[4/20] | batch[7/72] train_loss: 2.0583 | accuracy: 0.3392857142857143\n",
      "epoch[4/20] | batch[14/72] train_loss: 2.0769 | accuracy: 0.31026785714285715\n",
      "epoch[4/20] | batch[21/72] train_loss: 2.0541 | accuracy: 0.3482142857142857\n",
      "epoch[4/20] | batch[28/72] train_loss: 2.0693 | accuracy: 0.3325892857142857\n",
      "epoch[4/20] | batch[35/72] train_loss: 2.0786 | accuracy: 0.30580357142857145\n",
      "epoch[4/20] | batch[42/72] train_loss: 2.0541 | accuracy: 0.3169642857142857\n",
      "epoch[4/20] | batch[49/72] train_loss: 2.0488 | accuracy: 0.35267857142857145\n",
      "epoch[4/20] | batch[56/72] train_loss: 2.0380 | accuracy: 0.36160714285714285\n",
      "epoch[4/20] | batch[63/72] train_loss: 2.0575 | accuracy: 0.3125\n",
      "epoch[4/20] | batch[70/72] train_loss: 2.0632 | accuracy: 0.3125\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 4/20 [01:58<08:07, 30.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 summary:\n",
      " train_loss: 2.002669334411621, validation loss: 2.057671546936035, train accuracy: 0.3200954861111111\n",
      "epoch[5/20] | batch[7/72] train_loss: 2.0450 | accuracy: 0.3549107142857143\n",
      "epoch[5/20] | batch[14/72] train_loss: 2.0684 | accuracy: 0.3013392857142857\n",
      "epoch[5/20] | batch[21/72] train_loss: 2.0407 | accuracy: 0.36607142857142855\n",
      "epoch[5/20] | batch[28/72] train_loss: 2.0609 | accuracy: 0.32589285714285715\n",
      "epoch[5/20] | batch[35/72] train_loss: 2.0702 | accuracy: 0.30580357142857145\n",
      "epoch[5/20] | batch[42/72] train_loss: 2.0462 | accuracy: 0.328125\n",
      "epoch[5/20] | batch[49/72] train_loss: 2.0369 | accuracy: 0.36160714285714285\n",
      "epoch[5/20] | batch[56/72] train_loss: 2.0274 | accuracy: 0.3705357142857143\n",
      "epoch[5/20] | batch[63/72] train_loss: 2.0460 | accuracy: 0.3236607142857143\n",
      "epoch[5/20] | batch[70/72] train_loss: 2.0560 | accuracy: 0.3236607142857143\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████                                 | 5/20 [02:30<07:41, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 summary:\n",
      " train_loss: 1.9928452968597412, validation loss: 2.0497374534606934, train accuracy: 0.3268229166666667\n",
      "epoch[6/20] | batch[7/72] train_loss: 2.0375 | accuracy: 0.359375\n",
      "epoch[6/20] | batch[14/72] train_loss: 2.0624 | accuracy: 0.30357142857142855\n",
      "epoch[6/20] | batch[21/72] train_loss: 2.0311 | accuracy: 0.3638392857142857\n",
      "epoch[6/20] | batch[28/72] train_loss: 2.0547 | accuracy: 0.31919642857142855\n",
      "epoch[6/20] | batch[35/72] train_loss: 2.0630 | accuracy: 0.3236607142857143\n",
      "epoch[6/20] | batch[42/72] train_loss: 2.0414 | accuracy: 0.33035714285714285\n",
      "epoch[6/20] | batch[49/72] train_loss: 2.0289 | accuracy: 0.375\n",
      "epoch[6/20] | batch[56/72] train_loss: 2.0188 | accuracy: 0.37723214285714285\n",
      "epoch[6/20] | batch[63/72] train_loss: 2.0383 | accuracy: 0.3325892857142857\n",
      "epoch[6/20] | batch[70/72] train_loss: 2.0485 | accuracy: 0.328125\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 6/20 [03:01<07:12, 30.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 summary:\n",
      " train_loss: 1.9857373237609863, validation loss: 2.04314923286438, train accuracy: 0.3318142361111111\n",
      "epoch[7/20] | batch[7/72] train_loss: 2.0310 | accuracy: 0.35267857142857145\n",
      "epoch[7/20] | batch[14/72] train_loss: 2.0589 | accuracy: 0.30357142857142855\n",
      "epoch[7/20] | batch[21/72] train_loss: 2.0235 | accuracy: 0.35714285714285715\n",
      "epoch[7/20] | batch[28/72] train_loss: 2.0503 | accuracy: 0.3169642857142857\n",
      "epoch[7/20] | batch[35/72] train_loss: 2.0589 | accuracy: 0.31919642857142855\n",
      "epoch[7/20] | batch[42/72] train_loss: 2.0358 | accuracy: 0.33035714285714285\n",
      "epoch[7/20] | batch[49/72] train_loss: 2.0222 | accuracy: 0.37723214285714285\n",
      "epoch[7/20] | batch[56/72] train_loss: 2.0133 | accuracy: 0.37723214285714285\n",
      "epoch[7/20] | batch[63/72] train_loss: 2.0327 | accuracy: 0.328125\n",
      "epoch[7/20] | batch[70/72] train_loss: 2.0443 | accuracy: 0.33035714285714285\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████▍                            | 7/20 [03:32<06:42, 30.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 summary:\n",
      " train_loss: 1.9804922342300415, validation loss: 2.0390467643737793, train accuracy: 0.3298611111111111\n",
      "epoch[8/20] | batch[7/72] train_loss: 2.0256 | accuracy: 0.3482142857142857\n",
      "epoch[8/20] | batch[14/72] train_loss: 2.0557 | accuracy: 0.3080357142857143\n",
      "epoch[8/20] | batch[21/72] train_loss: 2.0164 | accuracy: 0.3638392857142857\n",
      "epoch[8/20] | batch[28/72] train_loss: 2.0471 | accuracy: 0.328125\n",
      "epoch[8/20] | batch[35/72] train_loss: 2.0553 | accuracy: 0.3125\n",
      "epoch[8/20] | batch[42/72] train_loss: 2.0319 | accuracy: 0.34375\n",
      "epoch[8/20] | batch[49/72] train_loss: 2.0154 | accuracy: 0.38392857142857145\n",
      "epoch[8/20] | batch[56/72] train_loss: 2.0097 | accuracy: 0.3705357142857143\n",
      "epoch[8/20] | batch[63/72] train_loss: 2.0278 | accuracy: 0.3325892857142857\n",
      "epoch[8/20] | batch[70/72] train_loss: 2.0397 | accuracy: 0.33035714285714285\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 8/20 [04:03<06:12, 31.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 summary:\n",
      " train_loss: 1.9760117530822754, validation loss: 2.034187078475952, train accuracy: 0.3326822916666667\n",
      "epoch[9/20] | batch[7/72] train_loss: 2.0215 | accuracy: 0.3482142857142857\n",
      "epoch[9/20] | batch[14/72] train_loss: 2.0528 | accuracy: 0.30580357142857145\n",
      "epoch[9/20] | batch[21/72] train_loss: 2.0108 | accuracy: 0.36607142857142855\n",
      "epoch[9/20] | batch[28/72] train_loss: 2.0438 | accuracy: 0.31919642857142855\n",
      "epoch[9/20] | batch[35/72] train_loss: 2.0511 | accuracy: 0.31026785714285715\n",
      "epoch[9/20] | batch[42/72] train_loss: 2.0283 | accuracy: 0.3392857142857143\n",
      "epoch[9/20] | batch[49/72] train_loss: 2.0104 | accuracy: 0.3705357142857143\n",
      "epoch[9/20] | batch[56/72] train_loss: 2.0048 | accuracy: 0.37723214285714285\n",
      "epoch[9/20] | batch[63/72] train_loss: 2.0237 | accuracy: 0.33482142857142855\n",
      "epoch[9/20] | batch[70/72] train_loss: 2.0347 | accuracy: 0.33035714285714285\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████▊                        | 9/20 [04:35<05:42, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 summary:\n",
      " train_loss: 1.9718413352966309, validation loss: 2.0306107997894287, train accuracy: 0.3307291666666667\n",
      "epoch[10/20] | batch[7/72] train_loss: 2.0172 | accuracy: 0.34598214285714285\n",
      "epoch[10/20] | batch[14/72] train_loss: 2.0490 | accuracy: 0.296875\n",
      "epoch[10/20] | batch[21/72] train_loss: 2.0061 | accuracy: 0.3705357142857143\n",
      "epoch[10/20] | batch[28/72] train_loss: 2.0407 | accuracy: 0.3125\n",
      "epoch[10/20] | batch[35/72] train_loss: 2.0477 | accuracy: 0.3125\n",
      "epoch[10/20] | batch[42/72] train_loss: 2.0262 | accuracy: 0.3482142857142857\n",
      "epoch[10/20] | batch[49/72] train_loss: 2.0041 | accuracy: 0.38392857142857145\n",
      "epoch[10/20] | batch[56/72] train_loss: 2.0018 | accuracy: 0.38169642857142855\n",
      "epoch[10/20] | batch[63/72] train_loss: 2.0162 | accuracy: 0.3392857142857143\n",
      "epoch[10/20] | batch[70/72] train_loss: 2.0274 | accuracy: 0.3392857142857143\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████▌                     | 10/20 [05:06<05:11, 31.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 summary:\n",
      " train_loss: 1.9674290418624878, validation loss: 2.02424955368042, train accuracy: 0.3335503472222222\n",
      "epoch[11/20] | batch[7/72] train_loss: 2.0123 | accuracy: 0.3482142857142857\n",
      "epoch[11/20] | batch[14/72] train_loss: 2.0443 | accuracy: 0.3013392857142857\n",
      "epoch[11/20] | batch[21/72] train_loss: 2.0006 | accuracy: 0.36607142857142855\n",
      "epoch[11/20] | batch[28/72] train_loss: 2.0370 | accuracy: 0.3125\n",
      "epoch[11/20] | batch[35/72] train_loss: 2.0422 | accuracy: 0.33482142857142855\n",
      "epoch[11/20] | batch[42/72] train_loss: 2.0244 | accuracy: 0.35267857142857145\n",
      "epoch[11/20] | batch[49/72] train_loss: 1.9976 | accuracy: 0.37723214285714285\n",
      "epoch[11/20] | batch[56/72] train_loss: 1.9972 | accuracy: 0.390625\n",
      "epoch[11/20] | batch[63/72] train_loss: 2.0104 | accuracy: 0.35267857142857145\n",
      "epoch[11/20] | batch[70/72] train_loss: 2.0199 | accuracy: 0.33482142857142855\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████▋                   | 11/20 [05:35<04:35, 30.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 summary:\n",
      " train_loss: 1.96250319480896, validation loss: 2.0184104442596436, train accuracy: 0.3374565972222222\n",
      "epoch[12/20] | batch[7/72] train_loss: 2.0070 | accuracy: 0.34598214285714285\n",
      "epoch[12/20] | batch[14/72] train_loss: 2.0388 | accuracy: 0.31026785714285715\n",
      "epoch[12/20] | batch[21/72] train_loss: 1.9949 | accuracy: 0.38169642857142855\n",
      "epoch[12/20] | batch[28/72] train_loss: 2.0339 | accuracy: 0.328125\n",
      "epoch[12/20] | batch[35/72] train_loss: 2.0398 | accuracy: 0.3392857142857143\n",
      "epoch[12/20] | batch[42/72] train_loss: 2.0218 | accuracy: 0.36160714285714285\n",
      "epoch[12/20] | batch[49/72] train_loss: 1.9902 | accuracy: 0.40848214285714285\n",
      "epoch[12/20] | batch[56/72] train_loss: 1.9928 | accuracy: 0.3950892857142857\n",
      "epoch[12/20] | batch[63/72] train_loss: 2.0054 | accuracy: 0.3638392857142857\n",
      "epoch[12/20] | batch[70/72] train_loss: 2.0130 | accuracy: 0.359375\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████▊                 | 12/20 [06:03<03:58, 29.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 summary:\n",
      " train_loss: 1.95781409740448, validation loss: 2.0126495361328125, train accuracy: 0.3493923611111111\n",
      "epoch[13/20] | batch[7/72] train_loss: 2.0020 | accuracy: 0.35714285714285715\n",
      "epoch[13/20] | batch[14/72] train_loss: 2.0331 | accuracy: 0.32142857142857145\n",
      "epoch[13/20] | batch[21/72] train_loss: 1.9901 | accuracy: 0.38392857142857145\n",
      "epoch[13/20] | batch[28/72] train_loss: 2.0313 | accuracy: 0.328125\n",
      "epoch[13/20] | batch[35/72] train_loss: 2.0369 | accuracy: 0.34375\n",
      "epoch[13/20] | batch[42/72] train_loss: 2.0207 | accuracy: 0.35714285714285715\n",
      "epoch[13/20] | batch[49/72] train_loss: 1.9854 | accuracy: 0.4174107142857143\n",
      "epoch[13/20] | batch[56/72] train_loss: 1.9906 | accuracy: 0.39285714285714285\n",
      "epoch[13/20] | batch[63/72] train_loss: 2.0007 | accuracy: 0.375\n",
      "epoch[13/20] | batch[70/72] train_loss: 2.0071 | accuracy: 0.3794642857142857\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████▉               | 13/20 [06:31<03:25, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 summary:\n",
      " train_loss: 1.9539637565612793, validation loss: 2.008204221725464, train accuracy: 0.35546875\n",
      "epoch[14/20] | batch[7/72] train_loss: 1.9979 | accuracy: 0.36830357142857145\n",
      "epoch[14/20] | batch[14/72] train_loss: 2.0290 | accuracy: 0.3325892857142857\n",
      "epoch[14/20] | batch[21/72] train_loss: 1.9860 | accuracy: 0.39285714285714285\n",
      "epoch[14/20] | batch[28/72] train_loss: 2.0289 | accuracy: 0.328125\n",
      "epoch[14/20] | batch[35/72] train_loss: 2.0336 | accuracy: 0.3482142857142857\n",
      "epoch[14/20] | batch[42/72] train_loss: 2.0178 | accuracy: 0.3549107142857143\n",
      "epoch[14/20] | batch[49/72] train_loss: 1.9815 | accuracy: 0.4263392857142857\n",
      "epoch[14/20] | batch[56/72] train_loss: 1.9869 | accuracy: 0.4017857142857143\n",
      "epoch[14/20] | batch[63/72] train_loss: 1.9973 | accuracy: 0.38392857142857145\n",
      "epoch[14/20] | batch[70/72] train_loss: 2.0026 | accuracy: 0.3794642857142857\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████             | 14/20 [06:59<02:53, 28.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 summary:\n",
      " train_loss: 1.9504151344299316, validation loss: 2.004056215286255, train accuracy: 0.361328125\n",
      "epoch[15/20] | batch[7/72] train_loss: 1.9944 | accuracy: 0.38392857142857145\n",
      "epoch[15/20] | batch[14/72] train_loss: 2.0258 | accuracy: 0.33035714285714285\n",
      "epoch[15/20] | batch[21/72] train_loss: 1.9829 | accuracy: 0.39732142857142855\n",
      "epoch[15/20] | batch[28/72] train_loss: 2.0264 | accuracy: 0.3392857142857143\n",
      "epoch[15/20] | batch[35/72] train_loss: 2.0316 | accuracy: 0.34375\n",
      "epoch[15/20] | batch[42/72] train_loss: 2.0146 | accuracy: 0.3638392857142857\n",
      "epoch[15/20] | batch[49/72] train_loss: 1.9773 | accuracy: 0.4263392857142857\n",
      "epoch[15/20] | batch[56/72] train_loss: 1.9843 | accuracy: 0.4017857142857143\n",
      "epoch[15/20] | batch[63/72] train_loss: 1.9947 | accuracy: 0.38839285714285715\n",
      "epoch[15/20] | batch[70/72] train_loss: 1.9977 | accuracy: 0.375\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████▎          | 15/20 [07:27<02:23, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 summary:\n",
      " train_loss: 1.9473446607589722, validation loss: 2.001546859741211, train accuracy: 0.3645833333333333\n",
      "epoch[16/20] | batch[7/72] train_loss: 1.9905 | accuracy: 0.3861607142857143\n",
      "epoch[16/20] | batch[14/72] train_loss: 2.0224 | accuracy: 0.34151785714285715\n",
      "epoch[16/20] | batch[21/72] train_loss: 1.9795 | accuracy: 0.39955357142857145\n",
      "epoch[16/20] | batch[28/72] train_loss: 2.0241 | accuracy: 0.33705357142857145\n",
      "epoch[16/20] | batch[35/72] train_loss: 2.0296 | accuracy: 0.33705357142857145\n",
      "epoch[16/20] | batch[42/72] train_loss: 2.0129 | accuracy: 0.36607142857142855\n",
      "epoch[16/20] | batch[49/72] train_loss: 1.9741 | accuracy: 0.4263392857142857\n",
      "epoch[16/20] | batch[56/72] train_loss: 1.9828 | accuracy: 0.4107142857142857\n",
      "epoch[16/20] | batch[63/72] train_loss: 1.9910 | accuracy: 0.3861607142857143\n",
      "epoch[16/20] | batch[70/72] train_loss: 1.9937 | accuracy: 0.3861607142857143\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████▍        | 16/20 [07:56<01:54, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 summary:\n",
      " train_loss: 1.9445027112960815, validation loss: 1.9990477561950684, train accuracy: 0.3671875\n",
      "epoch[17/20] | batch[7/72] train_loss: 1.9880 | accuracy: 0.3861607142857143\n",
      "epoch[17/20] | batch[14/72] train_loss: 2.0200 | accuracy: 0.35044642857142855\n",
      "epoch[17/20] | batch[21/72] train_loss: 1.9776 | accuracy: 0.4017857142857143\n",
      "epoch[17/20] | batch[28/72] train_loss: 2.0223 | accuracy: 0.3325892857142857\n",
      "epoch[17/20] | batch[35/72] train_loss: 2.0273 | accuracy: 0.33482142857142855\n",
      "epoch[17/20] | batch[42/72] train_loss: 2.0115 | accuracy: 0.3705357142857143\n",
      "epoch[17/20] | batch[49/72] train_loss: 1.9706 | accuracy: 0.43526785714285715\n",
      "epoch[17/20] | batch[56/72] train_loss: 1.9804 | accuracy: 0.4107142857142857\n",
      "epoch[17/20] | batch[63/72] train_loss: 1.9888 | accuracy: 0.38392857142857145\n",
      "epoch[17/20] | batch[70/72] train_loss: 1.9916 | accuracy: 0.390625\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████▌      | 17/20 [08:24<01:25, 28.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 summary:\n",
      " train_loss: 1.9423171281814575, validation loss: 1.996803879737854, train accuracy: 0.369140625\n",
      "epoch[18/20] | batch[7/72] train_loss: 1.9848 | accuracy: 0.39285714285714285\n",
      "epoch[18/20] | batch[14/72] train_loss: 2.0179 | accuracy: 0.35044642857142855\n",
      "epoch[18/20] | batch[21/72] train_loss: 1.9758 | accuracy: 0.40625\n",
      "epoch[18/20] | batch[28/72] train_loss: 2.0199 | accuracy: 0.33482142857142855\n",
      "epoch[18/20] | batch[35/72] train_loss: 2.0238 | accuracy: 0.34151785714285715\n",
      "epoch[18/20] | batch[42/72] train_loss: 2.0091 | accuracy: 0.37276785714285715\n",
      "epoch[18/20] | batch[49/72] train_loss: 1.9689 | accuracy: 0.43526785714285715\n",
      "epoch[18/20] | batch[56/72] train_loss: 1.9782 | accuracy: 0.4107142857142857\n",
      "epoch[18/20] | batch[63/72] train_loss: 1.9852 | accuracy: 0.38839285714285715\n",
      "epoch[18/20] | batch[70/72] train_loss: 1.9871 | accuracy: 0.38839285714285715\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████▋    | 18/20 [08:52<00:56, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 summary:\n",
      " train_loss: 1.9396449327468872, validation loss: 1.9945564270019531, train accuracy: 0.3715277777777778\n",
      "epoch[19/20] | batch[7/72] train_loss: 1.9829 | accuracy: 0.390625\n",
      "epoch[19/20] | batch[14/72] train_loss: 2.0161 | accuracy: 0.35267857142857145\n",
      "epoch[19/20] | batch[21/72] train_loss: 1.9734 | accuracy: 0.40401785714285715\n",
      "epoch[19/20] | batch[28/72] train_loss: 2.0194 | accuracy: 0.33705357142857145\n",
      "epoch[19/20] | batch[35/72] train_loss: 2.0224 | accuracy: 0.34598214285714285\n",
      "epoch[19/20] | batch[42/72] train_loss: 2.0070 | accuracy: 0.37276785714285715\n",
      "epoch[19/20] | batch[49/72] train_loss: 1.9658 | accuracy: 0.43973214285714285\n",
      "epoch[19/20] | batch[56/72] train_loss: 1.9756 | accuracy: 0.41517857142857145\n",
      "epoch[19/20] | batch[63/72] train_loss: 1.9833 | accuracy: 0.39732142857142855\n",
      "epoch[19/20] | batch[70/72] train_loss: 1.9852 | accuracy: 0.40401785714285715\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████▊  | 19/20 [09:21<00:28, 28.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 summary:\n",
      " train_loss: 1.9377329349517822, validation loss: 1.9930542707443237, train accuracy: 0.3752170138888889\n",
      "epoch[20/20] | batch[7/72] train_loss: 1.9804 | accuracy: 0.40848214285714285\n",
      "epoch[20/20] | batch[14/72] train_loss: 2.0136 | accuracy: 0.35267857142857145\n",
      "epoch[20/20] | batch[21/72] train_loss: 1.9714 | accuracy: 0.40625\n",
      "epoch[20/20] | batch[28/72] train_loss: 2.0183 | accuracy: 0.328125\n",
      "epoch[20/20] | batch[35/72] train_loss: 2.0194 | accuracy: 0.3392857142857143\n",
      "epoch[20/20] | batch[42/72] train_loss: 2.0058 | accuracy: 0.3705357142857143\n",
      "epoch[20/20] | batch[49/72] train_loss: 1.9630 | accuracy: 0.43973214285714285\n",
      "epoch[20/20] | batch[56/72] train_loss: 1.9747 | accuracy: 0.40848214285714285\n",
      "epoch[20/20] | batch[63/72] train_loss: 1.9808 | accuracy: 0.39732142857142855\n",
      "epoch[20/20] | batch[70/72] train_loss: 1.9832 | accuracy: 0.38839285714285715\n",
      "validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [09:49<00:00, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 summary:\n",
      " train_loss: 1.935753345489502, validation loss: 1.990588903427124, train accuracy: 0.3732638888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SERT(64,40, d_model=128,d_k= 16, heads=8,n_classes=9,n_encoders=1,dropout=0.001, n_hidden=768)\n",
    "train,test,val = train_test_val_split(my_set, 0.8, 0.8)\n",
    "\n",
    "# after splitting, we will define the dataloader\n",
    "train_dataloader = torchdata.DataLoader(dataset=train, batch_size=64)\n",
    "validation_dataloader = torchdata.DataLoader(dataset=val, batch_size=64, shuffle=True)\n",
    "test_dataloader = torchdata.DataLoader(dataset=test, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\n",
    "summary = model_train(model, train_dataloader, validation_dataloader, num_epochs=20, device=device, loss_fn=loss_fn, metric=loss_fn, optimizer=optimizer, ext_dir='./model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model name': 'SERT',\n",
       " 'device': 'cpu',\n",
       " 'loss_fn': CrossEntropyLoss(),\n",
       " 'metric': CrossEntropyLoss(),\n",
       " 'optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.0001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'num_epochs': 20,\n",
       " 'train_loss': [2.0179000430636935,\n",
       "  1.9505057864718967,\n",
       "  1.9333839416503906,\n",
       "  1.922779295179579,\n",
       "  1.9160296122233074,\n",
       "  1.909674538506402,\n",
       "  1.903909683227539,\n",
       "  1.897999233669705,\n",
       "  1.891326692369249,\n",
       "  1.8842809465196397,\n",
       "  1.8771105872260199,\n",
       "  1.8693923950195312,\n",
       "  1.8630299038357205,\n",
       "  1.8560740152994792,\n",
       "  1.848904503716363,\n",
       "  1.8416222466362848,\n",
       "  1.8360303243001301,\n",
       "  1.8309849633110895,\n",
       "  1.8260067833794489,\n",
       "  1.819424523247613],\n",
       " 'train_accuracy': [0.2868923611111111,\n",
       "  0.3630642361111111,\n",
       "  0.3721788194444444,\n",
       "  0.3821614583333333,\n",
       "  0.3895399305555556,\n",
       "  0.3973524305555556,\n",
       "  0.40234375,\n",
       "  0.4114583333333333,\n",
       "  0.4192708333333333,\n",
       "  0.4264322916666667,\n",
       "  0.4361979166666667,\n",
       "  0.4474826388888889,\n",
       "  0.4548611111111111,\n",
       "  0.4639756944444444,\n",
       "  0.4711371527777778,\n",
       "  0.4774305555555556,\n",
       "  0.4835069444444444,\n",
       "  0.4854600694444444,\n",
       "  0.4954427083333333,\n",
       "  0.4995659722222222],\n",
       " 'val_loss': [2.018275260925293,\n",
       "  1.9974294900894165,\n",
       "  1.9883564710617065,\n",
       "  1.9827450513839722,\n",
       "  1.9796559810638428,\n",
       "  1.9778172969818115,\n",
       "  1.9743516445159912,\n",
       "  1.9731545448303223,\n",
       "  1.9723362922668457,\n",
       "  1.969857096672058,\n",
       "  1.9702568054199219,\n",
       "  1.9697034358978271,\n",
       "  1.966929316520691,\n",
       "  1.9738229513168335,\n",
       "  1.97081458568573,\n",
       "  1.9701472520828247,\n",
       "  1.9691954851150513,\n",
       "  1.9739816188812256,\n",
       "  1.9752106666564941,\n",
       "  1.975757122039795],\n",
       " 'val_accuracy': [0.3654513888888889,\n",
       "  0.375,\n",
       "  0.3845486111111111,\n",
       "  0.3836805555555556,\n",
       "  0.3914930555555556,\n",
       "  0.390625,\n",
       "  0.3932291666666667,\n",
       "  0.3967013888888889,\n",
       "  0.3932291666666667,\n",
       "  0.3949652777777778,\n",
       "  0.3914930555555556,\n",
       "  0.3949652777777778,\n",
       "  0.3958333333333333,\n",
       "  0.3871527777777778,\n",
       "  0.390625,\n",
       "  0.3880208333333333,\n",
       "  0.3932291666666667,\n",
       "  0.3888888888888889,\n",
       "  0.3845486111111111,\n",
       "  0.3819444444444444],\n",
       " 'steps': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19],\n",
       " 'total_time': 633.20148229599}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(summary['steps'], summary['train_loss'])\n",
    "plt.plot(summary['steps'], summary['val_loss'])\n",
    "\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.show()\n",
    "len(summary['steps']) == len(summary['train_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(summary['steps'],summary['train_accuracy'],)\n",
    "plt.plot( summary['steps'],summary['val_accuracy'],)\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# 1. problem: small accuracy:\n",
    "## possible causes:\n",
    "\n",
    "- needs fine-tuning hyperparameters ( takes time )\n",
    "- features are not suitable ( takes experiments )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next step: optimize hyperparameters, and make comparisons among different decisions "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
